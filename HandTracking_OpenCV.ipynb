{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vintendohuynh/HandTrackingWorkshop/blob/main/HandTracking_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip3 uninstall opencv-python mediapipe numpy pyautogui\n",
        "\n",
        "pip3 install opencv-python mediapipe numpy pyautogui\n",
        "\n",
        "python3 hand_tracker.py\n",
        "\n",
        "ARCHFLAGS=\"-arch arm64\" pip3 install --force-reinstall opencv-python mediapipe numpy pyautogui -if not working and on mac with arm64 architecture"
      ],
      "metadata": {
        "id": "JDJW1BSOB9ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyautogui\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"Everything imported successfully!\")"
      ],
      "metadata": {
        "id": "NH6Kyw1IByMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
        "mpDraw = mp.solutions.drawing_utils"
      ],
      "metadata": {
        "id": "sVn2EyAlByCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = pyautogui.size()"
      ],
      "metadata": {
        "id": "EbXGynokB3yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoloM2K5BLuy"
      },
      "outputs": [],
      "source": [
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture a frame from the webcam\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Flip the frame horizontally for a mirror effect\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Display the frame in a window titled 'Output'\n",
        "    cv2.imshow('Output', frame)\n",
        "\n",
        "    # Exit the loop if 'q' is pressed in the OpenCV window\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the webcam and close any OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hand tracking\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    # capture webcame frame and shape (width and height)\n",
        "    ret, frame = cap.read()\n",
        "    # defining the frame\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    # -------- ADD THIS CODE NEXT ---------------\n",
        "    # have mediapipe hands predict hand landmarks\n",
        "    x, y, c = frame.shape\n",
        "    result = hands.process(frame)\n",
        "    # iterate through the predicted landmarks adjusting them to the window, and\n",
        "    # and outputting them to the opencv window\n",
        "    if result.multi_hand_landmarks:\n",
        "        landmarks = []\n",
        "        for handslms in result.multi_hand_landmarks:\n",
        "            for lm in handslms.landmark:\n",
        "                lmx = int(lm.x * x)\n",
        "                lmy = int(lm.y * y)\n",
        "                landmarks.append([lmx, lmy])\n",
        "            mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
        "    # ------- FINISHED ADDING NEW CODE ----------\n",
        "    cv2.imshow('Output', frame)\n",
        "    # if q is pressed, program exits\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "ksm0t04TBcSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OORJWznsB8mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving Cursor\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    # capture webcame frame and shape (width and height)\n",
        "    ret, frame = cap.read()\n",
        "    # defining the frame\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    x, y, c = frame.shape\n",
        "    # have mediapipe hands predict hand landmarks\n",
        "    result = hands.process(frame)\n",
        "    # iterate through the predicted landmarks adjusting them to the window, and\n",
        "    # and outputting them to the opencv window\n",
        "    if result.multi_hand_landmarks:\n",
        "        landmarks = []\n",
        "        for handslms in result.multi_hand_landmarks:\n",
        "            # take the 8th landmark (index finger point) and move the cursor to that landmarks x and y value\n",
        "            # ADD THE LINE BELOW NEXT\n",
        "            pyautogui.moveTo(int(handslms.landmark[8].x * s[0]), int(handslms.landmark[8].y * s[1]), _pause=False)\n",
        "            for lm in handslms.landmark:\n",
        "                lmx = int(lm.x * x)\n",
        "                lmy = int(lm.y * y)\n",
        "                landmarks.append([lmx, lmy])\n",
        "            mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "    cv2.imshow('Output', frame)\n",
        "    # if q is pressed, program exits\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "k4Hu-vEIBkw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clicking\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "# -------- ADD THIS VARIABLE ---------------\n",
        "last_click = 0\n",
        "while True:\n",
        "    # capture webcame frame and shape (width and height)\n",
        "    ret, frame = cap.read()\n",
        "    x, y, c = frame.shape\n",
        "    # defining the frame\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    # have mediapipe hands predict hand landmarks\n",
        "    result = hands.process(frame)\n",
        "    # iterate through the predicted landmarks adjusting them to the window, and\n",
        "    # and outputting them to the opencv window\n",
        "    if result.multi_hand_landmarks:\n",
        "        landmarks = []\n",
        "        for handslms in result.multi_hand_landmarks:\n",
        "            # take the 8th landmark (index finger point) and move the cursor to that landmarks x and y value\n",
        "            pyautogui.moveTo(int(handslms.landmark[8].x * s[0]), int(handslms.landmark[8].y * s[1]), _pause=False)\n",
        "\n",
        "            # -------- ADD THIS CODE NEXT ---------------\n",
        "            # Detect click gesture by calculating distance between thumb (landmark 4) and index (landmark 8)\n",
        "            thumb_x = int(handslms.landmark[4].x * s[0])\n",
        "            thumb_y = int(handslms.landmark[4].y * s[1])\n",
        "            distance = ((index_x - thumb_x) ** 2 + (index_y - thumb_y) ** 2) ** 0.5\n",
        "\n",
        "            # If distance is small enough, simulate a click\n",
        "            if distance < 40 and time.time() - last_click > 0.5:\n",
        "                pyautogui.click()\n",
        "                last_click = time.time()\n",
        "            # ------- FINISHED ADDING NEW CODE ----------\n",
        "\n",
        "            for lm in handslms.landmark:\n",
        "                lmx = int(lm.x * x)\n",
        "                lmy = int(lm.y * y)\n",
        "                landmarks.append([lmx, lmy])\n",
        "            mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
        "    cv2.imshow('Output', frame)\n",
        "    # if q is pressed, program exits\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "xMMQnEgtBliQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}